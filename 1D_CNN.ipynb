{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the CSV dataset\n",
    "def load_data(csv_path):\n",
    "    data = pd.read_csv(csv_path, low_memory=False)\n",
    "    data = data.sample(frac=1, random_state=42)  # Shuffle data\n",
    "    return data\n",
    "\n",
    "# Step 2: Prepare the dataset for 1D CNN\n",
    "def prepare_data(data):\n",
    "    label_col = None\n",
    "    for col in data.columns:\n",
    "        if \"label\" in col.lower() or \"class\" in col.lower() or \"attack\" in col.lower():\n",
    "            label_col = col\n",
    "            break\n",
    "\n",
    "    if label_col is None:\n",
    "        raise ValueError(\"No label column found in dataset. Check column names!\")\n",
    "\n",
    "    feature_columns = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if label_col in feature_columns:\n",
    "        feature_columns.remove(label_col)\n",
    "    \n",
    "    features = data[feature_columns].values.astype(np.float32)\n",
    "    labels = data[label_col].values.astype(int)\n",
    "    return features, labels\n",
    "\n",
    "# Step 3: Create a custom PyTorch Dataset class\n",
    "class DDoSDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx].unsqueeze(0), self.labels[idx]  # Add channel dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Load data, split into train, validation, and test sets\n",
    "data = load_data(\"/path/to/ddos_dataset.csv\")\n",
    "features, labels = prepare_data(data)\n",
    "\n",
    "train_feats, test_feats, train_labels, test_labels = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "train_feats, val_feats, train_labels, val_labels = train_test_split(train_feats, train_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataset = DDoSDataset(train_feats, train_labels)\n",
    "val_dataset = DDoSDataset(val_feats, val_labels)\n",
    "test_dataset = DDoSDataset(test_feats, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Define the 1D CNN model\n",
    "class CNN1D(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(CNN1D, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(32 * (input_size // 2 // 2), 64)\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.relu(self.conv1(x)))\n",
    "        x = self.pool(self.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Initialize model, loss, and optimizer\n",
    "input_size = features.shape[1]\n",
    "num_classes = len(set(labels))\n",
    "\n",
    "model = CNN1D(input_size, num_classes)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Train the model\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for features, labels in train_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader)}\")\n",
    "    return model\n",
    "\n",
    "model = train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Evaluate on test data\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for features, labels in test_loader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            outputs = model(features)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "evaluate_model(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
