{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the CSV dataset\n",
    "def load_data(csv_path):\n",
    "    data = pd.read_csv(csv_path, low_memory=False)\n",
    "    data = data.sample(frac=0.1, random_state=42)  # Shuffle data\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert numerical features to grayscale images\n",
    "def convert_to_image(data, save_dir):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # Identify the label column dynamically\n",
    "    label_col = None\n",
    "    for col in data.columns:\n",
    "        if \"label\" in col.lower() or \"class\" in col.lower() or \"attack\" in col.lower():\n",
    "            label_col = col\n",
    "            break\n",
    "\n",
    "    if label_col is None:\n",
    "        raise ValueError(\"No label column found in dataset. Check column names!\")\n",
    "\n",
    "    # Extract feature columns (excluding the label)\n",
    "    feature_columns = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    if label_col in feature_columns:\n",
    "        feature_columns.remove(label_col)\n",
    "\n",
    "    print(f\"Using label column: {label_col}\")  # Debugging output\n",
    "\n",
    "    images, labels = [], []\n",
    "    num_features = len(feature_columns)\n",
    "    image_size = math.ceil(math.sqrt(num_features))  # Find the next perfect square\n",
    "\n",
    "    for i, row in enumerate(data.iterrows()):\n",
    "        padded_features = np.pad(row[1][feature_columns].values, (0, image_size**2 - num_features), 'constant')\n",
    "        features = padded_features.reshape(image_size, image_size)\n",
    "        \n",
    "        img = Image.fromarray((features * 255).astype(np.uint8), mode='L')\n",
    "        img.save(f\"{save_dir}/img_{i}.png\")\n",
    "        images.append(f\"{save_dir}/img_{i}.png\")\n",
    "        labels.append(row[1][label_col])  # Use dynamically detected label column\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Create a custom PyTorch Dataset class\n",
    "class DDoSDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, torch.tensor(label, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Define data transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Load data, convert to images\n",
    "data = load_data(\"/Users/book_kuno/Downloads/DDoS 2018/02-21-2018.csv\")\n",
    "image_paths, labels = convert_to_image(data, \"./ddos_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Create DataLoaders\n",
    "train_dataset = DDoSDataset(train_imgs, train_labels, transform)\n",
    "val_dataset = DDoSDataset(val_imgs, val_labels, transform)\n",
    "test_dataset = DDoSDataset(test_imgs, test_labels, transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Load pre-trained ResNet-18 and modify it for DDoS detection\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 2)  # Binary classification\n",
    "model = model.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Train the model\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader)}\")\n",
    "    return model\n",
    "\n",
    "model = train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Evaluate on test data\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")), labels.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "evaluate_model(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
